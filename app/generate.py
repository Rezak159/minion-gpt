from openai import AsyncOpenAI
from ddgs import DDGS
import json
from urllib.parse import urlparse


from config import AI_TOKEN

MODEL=''
# xiaomi/mimo-v2-flash:free

ROUTER_MODEL = 'openai/gpt-oss-20b'
GENERATOR_MODEL = 'openai/gpt-oss-120b'


def format_results(all_results):
    seen_domains = set()
    deduped = []
    for res in all_results:
        domain = urlparse(res['href']).netloc
        if domain not in seen_domains:
            seen_domains.add(domain)
            deduped.append(res)
        if len(deduped) >= 9:  # Ð¢Ð¾Ð¿-9 ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ…
            break
    return "\n".join(f"- [{domain}] {res['title']}: {res['body']}" for res in deduped)


async def search_web(queries: list[str], max_results=3) -> str:
    """
    ÐŸÐ¾Ð¸ÑÐº Ð² DuckDuckGo.
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸.
    """
    results = []
    for i, query in enumerate(queries, 1):
        try:
            with DDGS() as ddgs:
                print(f"\nðŸ” [Tool] Ð˜Ñ‰Ñƒ Ð² Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ðµ: '{query}'...")
                r = list(ddgs.text(query, max_results=max_results))
                results.extend(r)
                if not results:
                    return "ÐŸÐ¾Ð¸ÑÐº Ð½Ðµ Ð´Ð°Ð» Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²."
                
                return format_results(results)  # Ð£Ð±Ñ€Ð°Ñ‚ÑŒ Ð´ÑƒÐ±Ð»Ð¸ + Ñ€Ð°Ð½Ð¶Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ

                
                results_text = "\n".join(
                    # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: [Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº] - Ð¢ÐµÐºÑÑ‚ (Ð±ÐµÐ· Ð³Ñ€Ð¾Ð¼Ð¾Ð·Ð´ÐºÐ¸Ñ… URL Ð¸ Ð¼ÐµÑ‚Ð¾Ðº)
                    f"- {res['title']}: {res['body']}" 
                    for res in results
                )
                print(results_text)
                return results_text
            
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ°: {e}")
            return f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð¸ÑÐºÐµ: {e}"


client = AsyncOpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=AI_TOKEN,
)



async def ai_generate(text: str, storage, user_id: int, chat_id: int, thread_id: int):
    """
    Ð£Ð¼Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸:
    1. Ð¡Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚ Ñ€Ð¾ÑƒÑ‚ÐµÑ€ (Ð½ÑƒÐ¶ÐµÐ½ Ð»Ð¸ Ð¿Ð¾Ð¸ÑÐº?)
    2. Ð˜Ñ‰ÐµÑ‚ (ÐµÑÐ»Ð¸ Ð½Ð°Ð´Ð¾)
    3. Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚ (ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³)
    """

    from datetime import datetime
    current_date = datetime.now().strftime("%d.%m.%Y %H:%M")

    router_messages = []
    router_messages.append({
        "role": "system", 
        "content": (
            f"Ð¡ÐµÐ³Ð¾Ð´Ð½Ñ {current_date}. Ð¢Ñ‹ â€” Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð². ÐŸÐ˜Ð¨Ð˜ Ð¢ÐžÐ›Ð¬ÐšÐž JSON.\n"
            "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸, Ð½ÑƒÐ¶Ð½Ð° Ð»Ð¸ ÑÐ²ÐµÐ¶Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¸Ð· ÑÐµÑ‚Ð¸.\n\n"
            
            "ÐŸÐ ÐÐ’Ð˜Ð›Ð Ð¤ÐžÐ ÐœÐ˜Ð ÐžÐ’ÐÐÐ˜Ð¯ Ð—ÐÐŸÐ ÐžÐ¡ÐžÐ’:\n"
            "1. Ð’Ð¡Ð•Ð“Ð”Ð Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²\n"
            "2. ÐŸÐµÑ€ÐµÐ²Ð¾Ð´Ð¸ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð³Ð¾Ñ€Ð¾Ð´Ð¾Ð², ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹, ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð½Ð° Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹\n"
            "3. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° (Ð½Ðµ Ð¿Ð¾Ð»Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ)\n"
            "4. Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ð´Ð°Ñ‚Ñ‹ Ð²Ð¼ÐµÑÑ‚Ð¾ 'ÑÐµÐ³Ð¾Ð´Ð½Ñ', 'Ð²Ñ‡ÐµÑ€Ð°', 'Ð·Ð°Ð²Ñ‚Ñ€Ð°'\n"
            
            "ÐŸÐ Ð˜ÐœÐ•Ð Ð«:\n"
            "âŒ 'Ð¿Ð¾Ð³Ð¾Ð´Ð° Ð¥Ð°Ð½Ñ‚Ñ‹-ÐœÐ°Ð½ÑÐ¸Ð¹ÑÐº ÑÐµÐ³Ð¾Ð´Ð½Ñ' â†’ âœ… 'Khanty-Mansiysk weather January 5 2026'\n"
            "âŒ 'ÐºÑ‚Ð¾ Ð²Ñ‡ÐµÑ€Ð° Ð¿Ð¾Ð±ÐµÐ´Ð¸Ð» Ð±Ð°Ñ€ÑÐµÐ»Ð¾Ð½Ñƒ' â†’ âœ… 'Barcelona match result 4 January 2026'\n"
            "âŒ 'Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð“Ð°Ð·Ð¿Ñ€Ð¾Ð¼' â†’ âœ… 'Gazprom news January 2026'\n"
            "âŒ 'ÐºÑƒÑ€Ñ Ð±Ð¸Ñ‚ÐºÐ¾Ð¸Ð½Ð°' â†’ âœ… 'Bitcoin price USD'\n\n"
            
            "Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€, Ð¾Ð±Ñ‰Ð¸Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ - Ð¿Ð¾Ð¸ÑÐº Ð½Ðµ Ð½ÑƒÐ¶ÐµÐ½.\n"
            "ÐžÑ‚Ð²ÐµÑ‚ ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð² JSON: "
            "{'search_needed': true, 'queries': ['base', 'with date', 'synonyms']}"
        )
        })
    
    history = await storage.load_history(user_id, chat_id, thread_id)
    history.append({"role": "user", "content": text})

    router_messages.extend(history)

    print("ðŸ¤– [Router] ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ð·Ð°Ð¿Ñ€Ð¾Ñ...")

    # response_format={"type": "json_object"} - ÑÑ‚Ð¾ Ñ„Ð¸Ñ‡Ð° Groq/OpenAI, Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÑŽÑ‰Ð°Ñ JSON Ð½Ð° Ð²Ñ‹Ñ…Ð¾Ð´Ðµ
    router_response = await client.chat.completions.create(
        model=ROUTER_MODEL,
        messages=router_messages,
        response_format={"type": "json_object"}, 
        temperature=0.3 # ÐÑƒÐ»ÐµÐ²Ð°Ñ Ñ‚ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð´Ð»Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·ÑƒÐµÐ¼Ð¾ÑÑ‚Ð¸
    )
    
    # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ð°
    try:
        decision_text = router_response.choices[0].message.content
        decision = json.loads(decision_text)
    except json.JSONDecodeError:
        # Ð•ÑÐ»Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ ÑÐ³Ð»ÑƒÐ¿Ð¸Ð»Ð° Ð¸ Ð²ÐµÑ€Ð½ÑƒÐ»Ð° Ð½Ðµ JSON (Ñ€ÐµÐ´ÐºÐ¾ Ñ response_format)
        print("âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° JSON Ð¾Ñ‚ Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ð°. Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¿Ð¾Ð¸ÑÐº Ð½Ðµ Ð½ÑƒÐ¶ÐµÐ½.")
        decision = {"search_needed": False}

    print(f"ðŸ’¡ [Router] Ð ÐµÑˆÐµÐ½Ð¸Ðµ: {decision}")

    # Ð­Ð¢ÐÐŸ 2: ÐŸÐžÐ˜Ð¡Ðš (Tool Execution)
    context_message = ""
    
    if decision.get("search_needed"):
        queries = decision.get("queries") or [decision.get("search_query", text)]
        search_results = await search_web(queries) 
        
        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        # ÐœÑ‹ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð¾ ÐºÐ°Ðº ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ user-ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚
        context_message = (
            f"Ð’Ð¾Ñ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ:\n"
            f"{search_results}\n\n"
            "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑÑ‚Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ."
        )

    final_messages = list(history)

    # Ð•ÑÐ»Ð¸ Ð±Ñ‹Ð» Ð¿Ð¾Ð¸ÑÐº, Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÐºÐ°Ðº ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÐŸÐ•Ð Ð•Ð” Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¼ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð¼
    if context_message:
        # Ð’ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÐºÐ°Ðº System message Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
        final_messages.append({"role": "system", "content": context_message})

    stream = await client.chat.completions.create(
        model=GENERATOR_MODEL,
        messages=final_messages,
        stream=True
        # tool_choice="auto",
        # tools=[{"type": "browser_search"}]
        )
    
    full_response = ''
    total_tokens = 0

    # print(response)
    # reasoning = response.choices[0].message.reasoning
    # answer = response.choices[0].message.content
    # tokens_used = response.usage.total_tokens

    # print(answer)

    # print(f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {tokens_used}")

    async for chunk in stream:
       content = chunk.choices[0].delta.content
       if content:
          # print(f'Ð§Ð°Ð½Ðº {content}')
          full_response += content
          yield content
       if chunk.usage:
           total_tokens = chunk.usage.total_tokens

    print(f"Ð˜Ñ‚Ð¾Ð³Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: {total_tokens}")

    history.append({"role": "assistant", "content": full_response})

    # ÐžÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 20 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ (10 Ð¿Ð°Ñ€ Ð²Ð¾Ð¿Ñ€Ð¾Ñ-Ð¾Ñ‚Ð²ÐµÑ‚)
    if len(history) > 20:
        history = history[-20:]

    await storage.save_history(user_id, chat_id, thread_id, history)

